# %% [markdown]
# # Earthquake NFO Distribution Visualization
# Description: This notebook fetches historical earthquake data from the EMIDIUS API for VRANCEA and visualizes earthquake distribution plots.
# Author(s): Jianu, Ovidiu; Matiddi, Ivano; Marmureanu, Alexandru; Festa, Gaetano; Chiaraluce, Lauro;
# References: Chiaraluce, Lauro, et al. "The Near Fault Observatory community in Europe: a new resource for faulting and hazard studies." Annals of Geophysics 65.3 (2022): DM316.
# Citation of notebook: see CITATION.cff file

# %% [markdown]
# ## 1. Fetching Earthquake Data

# %% [markdown]
# This section connects to the EMIDIUS API to retrieve historical earthquake data for Romania within the specified time frame (1000-1600 AD). It then processes the JSON response into a Pandas DataFrame for easier manipulation and analysis.

# %% 
import requests
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib.colors import Normalize
from datetime import datetime

# %% 
# API URL for historical earthquakes in Romania (1000-1600 AD)
API_URL = "https://emidius.eu/fdsnws/event/1/query"
params = {
    "starttime": "1000-01-01T00:00:00",
    "endtime": "1600-12-31T23:59:59",
    "minlatitude": 44.5,
    "maxlatitude": 46.5,
    "minlongitude": 24,
    "maxlongitude": 29,
    "format": "json",
    "includeallorigins": "false",
    "includeallmagnitudes": "false",
    "limit": 5000
}

print("Fetching earthquake data from API...")
response = requests.get(API_URL, params=params)

if response.status_code == 200:
    data = response.json()
    print(f"Successfully fetched {len(data['features'])} earthquakes")
else:
    print(f"Error fetching data: {response.status_code}")
    data = None

# %% [markdown]
# ## 2. Data Processing and Initial Analysis

# %% 
if data:
    # Extract earthquake data
    earthquakes = []

    for feature in data['features']:
        props = feature['properties']
        geom = feature['geometry']

        # Parse coordinates (longitude, latitude, depth)
        lon, lat = geom['coordinates'][0], geom['coordinates'][1]

        # Handle depth - some earthquakes might not have depth information
        depth = geom['coordinates'][2] if len(geom['coordinates']) > 2 else 0

        # Parse magnitude - handle missing magnitudes
        mag = props.get('mag', 0)

        # Parse time
        time_str = props.get('time', '')

        # Extract year from time string
        year = None
        if time_str:
            try:
                # Handle different time formats
                if 'T' in time_str:
                    date_part = time_str.split('T')[0]
                else:
                    date_part = time_str

                if len(date_part) >= 4:
                    year = int(date_part[:4])
            except:
                year = None

        earthquakes.append({
            'id': props['eventid'],
            'time': time_str,
            'year': year,
            'lon': lon,
            'lat': lat,
            'depth': depth,
            'mag': mag,
            'region': props.get('region', 'Unknown'),
            'magtype': props.get('magtype', 'Unknown'),
            'uncertainty': props.get('maguncertainty', 0)
        })

    # Create DataFrame
    df = pd.DataFrame(earthquakes)
    print("\nDataFrame Info:")
    print(df.info())
    print("\nFirst few records:")
    print(df.head())

    # Summary statistics
    print(f"\nTotal earthquakes: {len(df)}")
    print(f"Earliest year: {df['year'].min() if df['year'].notna().any() else 'Unknown'}")
    print(f"Latest year: {df['year'].max() if df['year'].notna().any() else 'Unknown'}")
    print(f"Magnitude range: {df['mag'].min():.1f} to {df['mag'].max():.1f}")
    print(f"Depth range: {df['depth'].min():.1f} to {df['depth'].max():.1f} km")

# %% [markdown]
# ## 3. 2D Visualizations and Analysis

# %% 
if data:
    # Create 2D plots
    fig = plt.figure(figsize=(16, 6))

    # Prepare data for plotting
    plot_data = df.copy()
    plot_data = plot_data[plot_data['year'].notna()]

    # Plot 1: Time series of earthquakes
    ax3 = fig.add_subplot(121) # Changed to 1 row, 2 columns, first plot

    if len(plot_data) > 0:
        # Group by year
        yearly_counts = plot_data.groupby('year').size()

        ax3.bar(yearly_counts.index, yearly_counts.values, width=1, alpha=0.7)
        ax3.set_xlabel('Year', fontsize=12)
        ax3.set_ylabel('Number of Earthquakes', fontsize=12)
        ax3.set_title('Earthquake Frequency Over Time', fontsize=14)
        ax3.grid(True, alpha=0.3)
        ax3.tick_params(axis='x', rotation=45)
    else:
        ax3.text(0.5, 0.5, "No valid year data available for time series",
                ha='center', va='center', transform=ax3.transAxes)

    # Plot 2: Depth vs Magnitude
    ax4 = fig.add_subplot(122) # Changed to 1 row, 2 columns, second plot

    if len(plot_data) > 0:
        years = plot_data['year'].values # Need years for color mapping
        scatter4 = ax4.scatter(
            plot_data['mag'],
            plot_data['depth'],
            c=years,
            cmap=cm.viridis,
            s=50,
            alpha=0.7,
            edgecolors='black',
            linewidth=0.5
        )

        ax4.set_xlabel('Magnitude (Mw)', fontsize=12)
        ax4.set_ylabel('Depth (km)', fontsize=12)
        ax4.set_title('Depth vs Magnitude', fontsize=14)
        ax4.grid(True, alpha=0.3)
        ax4.invert_yaxis()  # Invert y-axis so depth increases downward

        # Add colorbar
        cbar4 = plt.colorbar(scatter4, ax=ax4, shrink=0.8)
        cbar4.set_label('Year', fontsize=12)
    else:
        ax4.text(0.5, 0.5, "No valid data for Depth vs Magnitude",
                ha='center', va='center', transform=ax4.transAxes)

    plt.tight_layout()
    plt.show()

# %% 
if data:
    # Additional analysis: Depth distribution
    fig_depth, (ax1_depth, ax2_depth) = plt.subplots(1, 2, figsize=(14, 6))

    # Histogram of depths
    ax1_depth.hist(df['depth'].dropna(), bins=20, edgecolor='black', alpha=0.7)
    ax1_depth.set_xlabel('Depth (km)', fontsize=12)
    ax1_depth.set_ylabel('Frequency', fontsize=12)
    ax1_depth.set_title('Depth Distribution of Earthquakes', fontsize=14)
    ax1_depth.grid(True, alpha=0.3)

    # Boxplot of magnitudes by depth category
    df['depth_category'] = pd.cut(df['depth'],
                                   bins=[-1, 10, 50, 100, 200],
                                   labels=['Shallow (<10km)', 'Intermediate (10-50km)',
                                           'Deep (50-100km)', 'Very Deep (>100km)'])

    # Filter out NaN depth categories
    depth_data = df[df['depth_category'].notna()]

    if len(depth_data) > 0:
        categories = depth_data['depth_category'].cat.categories
        data_by_category = [depth_data[depth_data['depth_category'] == cat]['mag'].dropna()
                           for cat in categories]

        ax2_depth.boxplot(data_by_category, labels=categories)
        ax2_depth.set_xlabel('Depth Category', fontsize=12)
        ax2_depth.set_ylabel('Magnitude (Mw)', fontsize=12)
        ax2_depth.set_title('Magnitude Distribution by Depth Category', fontsize=14)
        ax2_depth.grid(True, alpha=0.3)
        ax2_depth.tick_params(axis='x', rotation=45)
    else:
        ax2_depth.text(0.5, 0.5, "No valid depth category data for boxplot",
                ha='center', va='center', transform=ax2_depth.transAxes)

    plt.tight_layout()
    plt.show()

# %% [markdown]
# ## 4. Summary Statistics

# %% 
# Print some interesting statistics
if data:
    print("\n" + "="*60)
    print("EARTHQUAKE DATA SUMMARY")
    print("="*60)

    # Top 5 strongest earthquakes
    top5 = df.nlargest(5, 'mag')
    print("\nTop 5 Strongest Earthquakes:")
    for idx, row in top5.iterrows():
        print(f"  {row['year']}: M{row['mag']:.1f} at {row['depth']:.0f} km depth")

    # Earthquakes by century
    df['century'] = (df['year'] // 100) * 100
    century_counts = df.groupby('century').size()

    print("\nEarthquakes by Century:")
    for century, count in century_counts.items():
        if not np.isnan(century):
            print(f"  {int(century)}s: {count} earthquakes")

    # Average magnitude by depth category
    if 'depth_category' in df.columns:
        avg_mag_by_depth = df.groupby('depth_category')['mag'].mean()
        print("\nAverage Magnitude by Depth Category:")
        for category, avg_mag in avg_mag_by_depth.items():
            if pd.notna(category) and pd.notna(avg_mag):
                print(f"  {category}: {avg_mag:.2f}")

    print("\n" + "="*60)
# decomment to generate requirements.txt list	
# !pip freeze > requirements.txt
